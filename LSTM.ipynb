{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "18c10e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f494dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6f592883",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_codes = ['M001', 'M002', 'M003', 'M004', 'M005', 'M006', 'M007', \n",
    "                'M008', 'M009', 'M010', 'M011', 'M012', 'M013', 'M014',\n",
    "                'M015', 'M016', 'M017', 'M018', 'M019', 'M020', 'M021', \n",
    "                'M022', 'M023', 'M024', 'M025', 'M026', 'M027', 'M028',\n",
    "                'M029', 'M030', 'D001', 'D002', 'D003', 'D004', 'T001',\n",
    "                'T002', 'T003', 'T004', 'T005']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8903eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    # dateset fields\n",
    "    timestamps = []\n",
    "    sensors = []\n",
    "    values = []\n",
    "    activities = []\n",
    "\n",
    "    current_activity = ''  # empty\n",
    "\n",
    "    with open(filename, 'rb') as features:\n",
    "        database = features.readlines()\n",
    "        \n",
    "        for i, line in enumerate(database):  # each line\n",
    "            f_info = line.decode().split()  # find fields\n",
    "            try:\n",
    "                if 'M' == f_info[2][0] or 'D' == f_info[2][0] or 'T' == f_info[2][0]:\n",
    "                    if str(np.array(f_info[2])) in sensor_codes:\n",
    "                        sensors.append(str(np.array(f_info[2])))\n",
    "                    else:\n",
    "                        continue\n",
    "                       \n",
    "                    if 'OFF' in f_info[3]:\n",
    "                        values.append('OFF')\n",
    "                    elif 'ON' in f_info[3]:\n",
    "                        values.append('ON')\n",
    "                    else:\n",
    "                        try:\n",
    "                            values.append(float(str(np.array(f_info[3]))))\n",
    "                        except ValueError:\n",
    "                            del sensors[-1]\n",
    "                            continue\n",
    "                            \n",
    "                    # choose only M D T sensors, avoiding unexpected errors\n",
    "                    if not ('.' in str(np.array(f_info[0])) + str(np.array(f_info[1]))):\n",
    "                        f_info[1] = f_info[1] + '.000000'\n",
    "                        \n",
    "                    try:\n",
    "                        timestamps.append(datetime.strptime(str(np.array(f_info[0])) + str(np.array(f_info[1])),\n",
    "                                                        \"%Y-%m-%d%H:%M:%S.%f\"))\n",
    "                    except ValueError:\n",
    "                        del sensors[-1]\n",
    "                        del values[-1]\n",
    "                        continue\n",
    "                        \n",
    "                    if len(f_info) == 4:  # if activity does not exist\n",
    "                        activities.append(current_activity)\n",
    "                    else:  # if activity exists\n",
    "                        des = str(' '.join(np.array(f_info[4:])))\n",
    "                        if 'begin' in des:\n",
    "                            current_activity = re.sub('begin', '', des)\n",
    "                            if current_activity[-1] == ' ':  # if white space at the end\n",
    "                                current_activity = current_activity[:-1]  # delete white space\n",
    "                            activities.append(current_activity)\n",
    "                        if 'end' in des:\n",
    "                            activities.append(current_activity)\n",
    "                            current_activity = ''\n",
    "            except IndexError:\n",
    "                print(i, line)\n",
    "                \n",
    "    features.close()\n",
    "    # dictionaries: assigning keys to values\n",
    "    temperature = []\n",
    "    for element in values:\n",
    "        try:\n",
    "            temperature.append(float(element))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return timestamps, sensors, values, activities, temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2499a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignKeysToValues(timestamps, sensors, values, activities, temperature):\n",
    "    \n",
    "    for i in range(0, len(values)):\n",
    "        values[i] = str(values[i]) ##VALUES TO STR\n",
    "    \n",
    "    sensorsList = sorted(set(sensors))\n",
    "    dictSensors = {}\n",
    "    for i, sensor in enumerate(sensorsList):\n",
    "        dictSensors[sensor] = i\n",
    "    activityList = sorted(set(activities))\n",
    "    dictActivities = {}\n",
    "    for i, activity in enumerate(activityList):\n",
    "        dictActivities[activity] = i\n",
    "    valueList = sorted(set(values))\n",
    "    dictValues = {}\n",
    "    for i, v in enumerate(valueList):\n",
    "        dictValues[v] = i\n",
    "    dictObs = {}\n",
    "    count = 0\n",
    "    for key in dictSensors.keys():\n",
    "        if \"M\" or \"AD\" in key:\n",
    "            dictObs[key + \"OFF\"] = count\n",
    "            count += 1\n",
    "            dictObs[key + \"ON\"] = count\n",
    "            count += 1\n",
    "        if \"D\" in key:\n",
    "            dictObs[key + \"CLOSE\"] = count\n",
    "            count += 1\n",
    "            dictObs[key + \"OPEN\"] = count\n",
    "            count += 1\n",
    "        if \"T\" in key:\n",
    "            for temp in range(0, int((max(temperature) - min(temperature)) * 2) + 1):\n",
    "                dictObs[key + str(float(temp / 2.0) + min(temperature))] = count + temp\n",
    "\n",
    "    XX = []\n",
    "    YY = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    for kk, s in enumerate(sensors):\n",
    "        if \"T\" in s:\n",
    "            try:\n",
    "                XX.append(dictObs[s + str(round(float(values[kk]), 1))])\n",
    "            except Exception:\n",
    "                if len(XX) > 0:\n",
    "                    XX.append(XX[-1])\n",
    "                else:\n",
    "                    XX.append(0)\n",
    "                \n",
    "        else:\n",
    "            try:\n",
    "                XX.append(dictObs[s + str(values[kk])])\n",
    "            except Exception:\n",
    "                if len(XX) > 0:\n",
    "                    XX.append(XX[-1])\n",
    "                else:\n",
    "                    XX.append(0)\n",
    "        YY.append(dictActivities[activities[kk]])\n",
    "\n",
    "    x = []\n",
    "    for i, y in enumerate(YY):\n",
    "        if i == 0:\n",
    "            Y.append(y)\n",
    "            x = [XX[i]]\n",
    "        if i > 0:\n",
    "            if y == YY[i - 1]:\n",
    "                x.append(XX[i])\n",
    "            else:\n",
    "                Y.append(y)\n",
    "                X.append(x)\n",
    "                x = [XX[i]]\n",
    "        if i == len(YY) - 1:\n",
    "            if y != YY[i - 1]:\n",
    "                Y.append(y)\n",
    "            X.append(x)\n",
    "    return X, Y, dictActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a2f402b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition_labels(aruba_set):\n",
    "    new_activity = ''\n",
    "    previous_activity = ''\n",
    "    \n",
    "    for i, entry in enumerate(aruba_set[3]): \n",
    "        if entry == '':\n",
    "            if new_activity != '':\n",
    "                aruba_set[3][i] = new_activity\n",
    "            else:\n",
    "                for next_entry in aruba_set[3][i:]:\n",
    "                    if next_entry != '':\n",
    "                        new_activity = 'Transition_' + previous_activity + '_' + next_entry\n",
    "                        aruba_set[3][i] = new_activity\n",
    "                        break            \n",
    "        else:\n",
    "            previous_activity = entry\n",
    "            new_activity = ''\n",
    "    return aruba_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5fbe269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aruba_dataset = load_dataset(\"./datasets/aruba/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4b03c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "aruba_dataset = add_transition_labels(aruba_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "29962c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1709857, 1709857, 1709857, 1709857, 1709857)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aruba_dataset[0]), len(aruba_dataset[1]), len(aruba_dataset[2]), len(aruba_dataset[3]), len(aruba_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b7be10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, dictActivities = AssignKeysToValues(aruba_dataset[0], aruba_dataset[1], aruba_dataset[2], aruba_dataset[3], aruba_dataset[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7c89f46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bed_to_Toilet': 0,\n",
       " 'Eating': 1,\n",
       " 'Enter_Home': 2,\n",
       " 'Housekeeping': 3,\n",
       " 'Leave_Home': 4,\n",
       " 'Meal_Preparation': 5,\n",
       " 'Relax': 6,\n",
       " 'Respirate': 7,\n",
       " 'Sleeping': 8,\n",
       " 'Transition_Bed_to_Toilet_Bed_to_Toilet': 9,\n",
       " 'Transition_Bed_to_Toilet_Meal_Preparation': 10,\n",
       " 'Transition_Bed_to_Toilet_Sleeping': 11,\n",
       " 'Transition_Eating_Eating': 12,\n",
       " 'Transition_Eating_Enter_Home': 13,\n",
       " 'Transition_Eating_Meal_Preparation': 14,\n",
       " 'Transition_Eating_Relax': 15,\n",
       " 'Transition_Eating_Sleeping': 16,\n",
       " 'Transition_Eating_Wash_Dishes': 17,\n",
       " 'Transition_Eating_Work': 18,\n",
       " 'Transition_Enter_Home_Relax': 19,\n",
       " 'Transition_Leave_Home_Meal_Preparation': 20,\n",
       " 'Transition_Meal_Preparation_Eating': 21,\n",
       " 'Transition_Meal_Preparation_Leave_Home': 22,\n",
       " 'Transition_Meal_Preparation_Meal_Preparation': 23,\n",
       " 'Transition_Meal_Preparation_Relax': 24,\n",
       " 'Transition_Meal_Preparation_Respirate': 25,\n",
       " 'Transition_Meal_Preparation_Work': 26,\n",
       " 'Transition_Relax_Eating': 27,\n",
       " 'Transition_Relax_Enter_Home': 28,\n",
       " 'Transition_Relax_Housekeeping': 29,\n",
       " 'Transition_Relax_Leave_Home': 30,\n",
       " 'Transition_Relax_Meal_Preparation': 31,\n",
       " 'Transition_Relax_Relax': 32,\n",
       " 'Transition_Relax_Respirate': 33,\n",
       " 'Transition_Relax_Sleeping': 34,\n",
       " 'Transition_Relax_Wash_Dishes': 35,\n",
       " 'Transition_Relax_Work': 36,\n",
       " 'Transition_Respirate_Meal_Preparation': 37,\n",
       " 'Transition_Respirate_Relax': 38,\n",
       " 'Transition_Sleeping_Bed_to_Toilet': 39,\n",
       " 'Transition_Sleeping_Meal_Preparation': 40,\n",
       " 'Transition_Sleeping_Relax': 41,\n",
       " 'Transition_Sleeping_Sleeping': 42,\n",
       " 'Transition_Wash_Dishes_Eating': 43,\n",
       " 'Transition_Wash_Dishes_Meal_Preparation': 44,\n",
       " 'Transition_Wash_Dishes_Relax': 45,\n",
       " 'Transition_Wash_Dishes_Wash_Dishes': 46,\n",
       " 'Transition_Wash_Dishes_Work': 47,\n",
       " 'Transition_Work_Eating': 48,\n",
       " 'Transition_Work_Meal_Preparation': 49,\n",
       " 'Transition_Work_Relax': 50,\n",
       " 'Transition_Work_Respirate': 51,\n",
       " 'Transition_Work_Sleeping': 52,\n",
       " 'Transition_Work_Wash_Dishes': 53,\n",
       " 'Transition_Work_Work': 54,\n",
       " 'Wash_Dishes': 55,\n",
       " 'Work': 56}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "95b9fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11056, 11056, 57)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), len(dictActivities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1493dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_2000 = sequence.pad_sequences(X, maxlen=2000, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a382ba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'8': 401, '39': 132, '0': 157, '11': 145, '40': 211, '5': 1606, '23': 623, '24': 731, '6': 2918, '31': 621, '21': 167, '1': 257, '12': 31, '17': 36, '55': 65, '45': 48, '18': 13, '56': 171, '50': 64, '27': 17, '47': 7, '52': 5, '26': 26, '54': 42, '36': 82, '29': 3, '3': 4, '43': 1, '15': 105, '32': 1921, '14': 57, '49': 54, '48': 3, '34': 223, '46': 1, '42': 16, '25': 1, '7': 6, '38': 4, '16': 2, '33': 4, '44': 8, '35': 23, '41': 18, '28': 3, '2': 5, '19': 1, '9': 2, '13': 2, '30': 1, '4': 3, '20': 1, '22': 2, '53': 2, '51': 1, '37': 2, '10': 1}\n"
     ]
    }
   ],
   "source": [
    "#delete labels that appear only once\n",
    "mp = {}\n",
    "for i in range(0, len(Y)):\n",
    "    mp[str(Y[i])] = 0\n",
    "\n",
    "for i in range(0, len(Y)):\n",
    "    mp[str(Y[i])] += 1\n",
    "    \n",
    "print(mp)\n",
    "LEN = len(Y)\n",
    "i = 0\n",
    "while i < LEN:\n",
    "    if mp[str(Y[i])] <= 1:\n",
    "        for x in dictActivities.keys():\n",
    "            if dictActivities[x] == Y[i]: \n",
    "                del dictActivities[x]\n",
    "                break\n",
    "        Y = np.delete(Y, i)\n",
    "        X_padded_2000 = np.delete(X_padded_2000, i, axis=0)\n",
    "        LEN -= 1\n",
    "        \n",
    "    else:\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ad726190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11048, 11048, 49)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_padded_2000), len(Y), len(dictActivities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fb86a2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8': 401,\n",
       " '39': 132,\n",
       " '0': 157,\n",
       " '11': 145,\n",
       " '40': 211,\n",
       " '5': 1606,\n",
       " '23': 623,\n",
       " '24': 731,\n",
       " '6': 2918,\n",
       " '31': 621,\n",
       " '21': 167,\n",
       " '1': 257,\n",
       " '12': 31,\n",
       " '17': 36,\n",
       " '55': 65,\n",
       " '45': 48,\n",
       " '18': 13,\n",
       " '56': 171,\n",
       " '50': 64,\n",
       " '27': 17,\n",
       " '47': 7,\n",
       " '52': 5,\n",
       " '26': 26,\n",
       " '54': 42,\n",
       " '36': 82,\n",
       " '29': 3,\n",
       " '3': 4,\n",
       " '15': 105,\n",
       " '32': 1921,\n",
       " '14': 57,\n",
       " '49': 54,\n",
       " '48': 3,\n",
       " '34': 223,\n",
       " '42': 16,\n",
       " '7': 6,\n",
       " '38': 4,\n",
       " '16': 2,\n",
       " '33': 4,\n",
       " '44': 8,\n",
       " '35': 23,\n",
       " '41': 18,\n",
       " '28': 3,\n",
       " '2': 5,\n",
       " '9': 2,\n",
       " '13': 2,\n",
       " '4': 3,\n",
       " '22': 2,\n",
       " '53': 2,\n",
       " '37': 2}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = {}\n",
    "for i in range(0, len(Y)):\n",
    "    mp[str(Y[i])] = 0\n",
    "\n",
    "for i in range(0, len(Y)):\n",
    "    mp[str(Y[i])] += 1\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4e580a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bed_to_Toilet': 0,\n",
       " 'Eating': 1,\n",
       " 'Enter_Home': 2,\n",
       " 'Housekeeping': 3,\n",
       " 'Leave_Home': 4,\n",
       " 'Meal_Preparation': 5,\n",
       " 'Relax': 6,\n",
       " 'Respirate': 7,\n",
       " 'Sleeping': 8,\n",
       " 'Transition_Bed_to_Toilet_Bed_to_Toilet': 9,\n",
       " 'Transition_Bed_to_Toilet_Sleeping': 11,\n",
       " 'Transition_Eating_Eating': 12,\n",
       " 'Transition_Eating_Enter_Home': 13,\n",
       " 'Transition_Eating_Meal_Preparation': 14,\n",
       " 'Transition_Eating_Relax': 15,\n",
       " 'Transition_Eating_Sleeping': 16,\n",
       " 'Transition_Eating_Wash_Dishes': 17,\n",
       " 'Transition_Eating_Work': 18,\n",
       " 'Transition_Meal_Preparation_Eating': 21,\n",
       " 'Transition_Meal_Preparation_Leave_Home': 22,\n",
       " 'Transition_Meal_Preparation_Meal_Preparation': 23,\n",
       " 'Transition_Meal_Preparation_Relax': 24,\n",
       " 'Transition_Meal_Preparation_Work': 26,\n",
       " 'Transition_Relax_Eating': 27,\n",
       " 'Transition_Relax_Enter_Home': 28,\n",
       " 'Transition_Relax_Housekeeping': 29,\n",
       " 'Transition_Relax_Meal_Preparation': 31,\n",
       " 'Transition_Relax_Relax': 32,\n",
       " 'Transition_Relax_Respirate': 33,\n",
       " 'Transition_Relax_Sleeping': 34,\n",
       " 'Transition_Relax_Wash_Dishes': 35,\n",
       " 'Transition_Relax_Work': 36,\n",
       " 'Transition_Respirate_Meal_Preparation': 37,\n",
       " 'Transition_Respirate_Relax': 38,\n",
       " 'Transition_Sleeping_Bed_to_Toilet': 39,\n",
       " 'Transition_Sleeping_Meal_Preparation': 40,\n",
       " 'Transition_Sleeping_Relax': 41,\n",
       " 'Transition_Sleeping_Sleeping': 42,\n",
       " 'Transition_Wash_Dishes_Meal_Preparation': 44,\n",
       " 'Transition_Wash_Dishes_Relax': 45,\n",
       " 'Transition_Wash_Dishes_Work': 47,\n",
       " 'Transition_Work_Eating': 48,\n",
       " 'Transition_Work_Meal_Preparation': 49,\n",
       " 'Transition_Work_Relax': 50,\n",
       " 'Transition_Work_Sleeping': 52,\n",
       " 'Transition_Work_Wash_Dishes': 53,\n",
       " 'Transition_Work_Work': 54,\n",
       " 'Wash_Dishes': 55,\n",
       " 'Work': 56}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "df7c6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_LSTM.npy', X_padded_2000)\n",
    "np.save('y_LSTM.npy', Y)\n",
    "np.save('Labels_LSTM.npy', dictActivities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "81d18b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X_LSTM.npy', allow_pickle=True)\n",
    "Y = np.load('y_LSTM.npy')\n",
    "dictActivities = np.load('Labels_LSTM.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fbb67a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bed_to_Toilet': 0,\n",
       " 'Eating': 1,\n",
       " 'Enter_Home': 2,\n",
       " 'Housekeeping': 3,\n",
       " 'Leave_Home': 4,\n",
       " 'Meal_Preparation': 5,\n",
       " 'Relax': 6,\n",
       " 'Respirate': 7,\n",
       " 'Sleeping': 8,\n",
       " 'Transition_Bed_to_Toilet_Bed_to_Toilet': 9,\n",
       " 'Transition_Bed_to_Toilet_Meal_Preparation': 10,\n",
       " 'Transition_Bed_to_Toilet_Sleeping': 11,\n",
       " 'Transition_Eating_Eating': 12,\n",
       " 'Transition_Eating_Enter_Home': 13,\n",
       " 'Transition_Eating_Meal_Preparation': 14,\n",
       " 'Transition_Eating_Relax': 15,\n",
       " 'Transition_Eating_Sleeping': 16,\n",
       " 'Transition_Eating_Wash_Dishes': 17,\n",
       " 'Transition_Eating_Work': 18,\n",
       " 'Transition_Enter_Home_Relax': 19,\n",
       " 'Transition_Leave_Home_Meal_Preparation': 20,\n",
       " 'Transition_Meal_Preparation_Eating': 21,\n",
       " 'Transition_Meal_Preparation_Leave_Home': 22,\n",
       " 'Transition_Meal_Preparation_Meal_Preparation': 23,\n",
       " 'Transition_Meal_Preparation_Relax': 24,\n",
       " 'Transition_Meal_Preparation_Respirate': 25,\n",
       " 'Transition_Meal_Preparation_Work': 26,\n",
       " 'Transition_Relax_Eating': 27,\n",
       " 'Transition_Relax_Enter_Home': 28,\n",
       " 'Transition_Relax_Housekeeping': 29,\n",
       " 'Transition_Relax_Leave_Home': 30,\n",
       " 'Transition_Relax_Meal_Preparation': 31,\n",
       " 'Transition_Relax_Relax': 32,\n",
       " 'Transition_Relax_Respirate': 33,\n",
       " 'Transition_Relax_Sleeping': 34,\n",
       " 'Transition_Relax_Wash_Dishes': 35,\n",
       " 'Transition_Relax_Work': 36,\n",
       " 'Transition_Respirate_Meal_Preparation': 37,\n",
       " 'Transition_Respirate_Relax': 38,\n",
       " 'Transition_Sleeping_Bed_to_Toilet': 39,\n",
       " 'Transition_Sleeping_Meal_Preparation': 40,\n",
       " 'Transition_Sleeping_Relax': 41,\n",
       " 'Transition_Sleeping_Sleeping': 42,\n",
       " 'Transition_Wash_Dishes_Eating': 43,\n",
       " 'Transition_Wash_Dishes_Meal_Preparation': 44,\n",
       " 'Transition_Wash_Dishes_Relax': 45,\n",
       " 'Transition_Wash_Dishes_Wash_Dishes': 46,\n",
       " 'Transition_Wash_Dishes_Work': 47,\n",
       " 'Transition_Work_Eating': 48,\n",
       " 'Transition_Work_Meal_Preparation': 49,\n",
       " 'Transition_Work_Relax': 50,\n",
       " 'Transition_Work_Respirate': 51,\n",
       " 'Transition_Work_Sleeping': 52,\n",
       " 'Transition_Work_Wash_Dishes': 53,\n",
       " 'Transition_Work_Work': 54,\n",
       " 'Wash_Dishes': 55,\n",
       " 'Work': 56}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "74d12a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5bdac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSTM(input_dim, output_dim, max_lenght, no_activities):\n",
    "    model = Sequential(name='LSTM')\n",
    "    model.add(Embedding(input_dim, output_dim, input_length=max_lenght, mask_zero=True))\n",
    "    model.add(LSTM(output_dim))\n",
    "    model.add(Dense(no_activities, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d81111ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileModel(model):\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1b2f75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "units = 64\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f052fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b7dddf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b1b93975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladbucur/miniconda3/envs/test/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 2000, 64)          707072    \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 57)                3705      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 743,801\n",
      "Trainable params: 743,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Begin training ...\n",
      "11/93 [==>...........................] - ETA: 1:16 - loss: 3.9948 - accuracy: 0.3665"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cl/4vy7vw1s77lb6xv7p52r8r140000gn/T/ipykernel_81194/2878817441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     model.fit(X_train_input, y_train, validation_split=0.2, epochs=epochs, batch_size=64, verbose=1,\n\u001b[0m\u001b[1;32m     29\u001b[0m           callbacks=[csv_logger, model_checkpoint])\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset=\"aruba\"\n",
    "cvaccuracy = []\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    input_dim = len(X)\n",
    "    X_train_input = X_train\n",
    "    X_test_input = X_test\n",
    "    no_activities = 57\n",
    "\n",
    "    model = get_LSTM(input_dim, units, 2000, no_activities)\n",
    "    model = compileModel(model)\n",
    "\n",
    "    modelname = \"LSTM\"\n",
    "    currenttime = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "    csv_logger = CSVLogger(\n",
    "    model.name + '-' + dataset + '-' + str(currenttime) + '.csv')\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "    model.name + '-' + dataset + '-' + str(currenttime) + '.h5',\n",
    "    monitor='acc',\n",
    "    save_best_only=True)\n",
    "\n",
    "    # train the model\n",
    "    print('Begin training ...')\n",
    "\n",
    "\n",
    "    model.fit(X_train_input, y_train, validation_split=0.2, epochs=epochs, batch_size=64, verbose=1,\n",
    "          callbacks=[csv_logger, model_checkpoint])\n",
    "\n",
    "    # evaluate the model\n",
    "    print('Begin testing ...')\n",
    "    scores = model.evaluate(X_test_input, y_test, batch_size=64, verbose=1)\n",
    "    print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "    print('Report:')\n",
    "    target_names = sorted(dictActivities, key=dictActivities.get)\n",
    "\n",
    "    predict_x = model.predict(X)\n",
    "    classes=np.argmax(predict_x,axis=-1)\n",
    "\n",
    "    print(classification_report(list(Y), classes, target_names=target_names))\n",
    "    print('Confusion matrix:')\n",
    "    labels = list(dictActivities.values())\n",
    "    print(confusion_matrix(list(Y), classes, labels=labels))\n",
    "\n",
    "    cvaccuracy.append(scores[1] * 100)\n",
    "    cvscores.append(scores)\n",
    "\n",
    "    k += 1\n",
    "\n",
    "print('{:.2f}% (+/- {:.2f}%)'.format(np.mean(cvaccuracy), np.std(cvaccuracy)))\n",
    "\n",
    "currenttime = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "csvfile = 'cv-scores-' + modelname + '-' + dataset + '-' + str(currenttime) + '.csv'\n",
    "\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in cvscores:\n",
    "        writer.writerow([\",\".join(str(el) for el in val)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c3fb437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 77s 222ms/step - loss: 0.3312 - accuracy: 0.9332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33119869232177734, 0.9331584572792053]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fc6f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1eb5229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb784cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = load_model('my_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
